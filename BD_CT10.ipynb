{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apache Spark is an open-source framework that can speedily handle processing Big Data in a single machine or cluster of machines. It supports Python language through the Pyspark library, which allows for scalable analysis and machine learning pipelines [1].\n",
    "\n",
    "- In this Python Notebook, we will use Pyspark to perform sentiment analysis on the movies reviews dataset in 5 main steps:\n",
    "1. Install then import the needed packages, and then Connet to the Spark cluster. \n",
    "2. load the dataset into Spark.\n",
    "3. Perform basic EDA.\n",
    "4. Preprocessing.\n",
    "5. Build a prodection model (Logestic Regrision Model) [2]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install then import the needed packages, and then Connet to the Spark cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To work with PySpark, we should first check if we have the java installed in our machine, and to do that, we can write this line in the command prompt shell 'java -version', the output will be something like this 'java version \"1.8.0_271\".\n",
    "\n",
    "- The next step is to install PySpark either from the Apache Spark download page or by using a pip install line in Jupyter.\n",
    "- Install findspark and import it to use its init() function to identify the path where Spark has installed.\n",
    "\n",
    "- Then import PySpark as ps to create SparkContext, the access point to the Spark cluster, and then create SQLContext, the access point to the Spark SQL to work with structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the location of spark in my device.\n",
    "\n",
    "SPARK_HOME = (r'C:\\Users\\sweet\\anaconda3\\Lib\\site-packages\\spark-3.1.1-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the needed libraries.\n",
    "\n",
    "import findspark\n",
    "findspark.init(SPARK_HOME)\n",
    "import pyspark as ps\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SparkContext that allow accessing the Spark cluster,\n",
    "# then create SQLContext to initialize SparkSQL functionality that can be recieved from SparkContext.\n",
    "\n",
    "sc = ps.SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. load the dataset into Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the training, validation, and testing datasets into Spark using\n",
    "# load() function with the path where the dataset is saved.\n",
    "\n",
    "df = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".options(header='true', inferSchema='true', multiLine='true', escape='\"').load(r'C:\\Users\\sweet\\Desktop\\Train.csv')\n",
    "\n",
    "valid = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".options(header='true', inferSchema='true', multiLine='true', escape='\"').load(r'C:\\Users\\sweet\\Desktop\\Valid.csv')\n",
    "\n",
    "test = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    ".options(header='true', inferSchema='true', multiLine='true', escape='\"').load(r'C:\\Users\\sweet\\Desktop\\Test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Perform basic Exploratory Data Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1. Its schema shows two columns: text of string data type and the label with an integer data type.\n",
    "- 2. The show function shows the first N rows of the dataframe; we notice that the text column is multiline text.\n",
    "- 3. We then use the isnan() function to count() the null values; here, the output is 0, indicating no missing values in our dataframe.\n",
    "- 4. The count of the training set is 40.000, the validation set is 5000, and the testing set is 5000.\n",
    "- 5. Use describe() function to perform basic statistics on the numeric column such as the mean, std, min, max, and count. Here we notice that the label column has just two values (binary), 0 and 1.\n",
    "- 6. Using the groupBy() function, we can group all reviews equal to label 1 in one group and reviews that equal to 0 in another one, and then we aggregate them by summing their count.\n",
    "- 7. We can show the first reviews in the dataframe by using the where() function. It defines a condition that shows the reviews equal to label 1, indicating positive reviews, and showing those equal to 0 indicating negative reviews. We can see that negative reviews are slightly more than negative reviews.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. show the dataframe schema\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|I grew up (b. 196...|    0|\n",
      "|When I put this m...|    0|\n",
      "|Why do people who...|    0|\n",
      "|Even though I hav...|    0|\n",
      "|Im a die hard Dad...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. show the first 5 rows of the dataframe\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|It's been about 1...|    0|\n",
      "|someone needed to...|    0|\n",
      "|The Guidelines st...|    0|\n",
      "|This movie is a m...|    0|\n",
      "|Before Stan Laure...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "valid.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|I always wrote th...|    0|\n",
      "|1st watched 12/7/...|    0|\n",
      "|This movie was so...|    0|\n",
      "|The most interest...|    1|\n",
      "|when i first read...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|text|label|\n",
      "+----+-----+\n",
      "|   0|    0|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. check for missing values\n",
    "\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "df.select([count(when(isnan(text), text)).alias(text) for text in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40000, 5000, 5000]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. count each dataset entries\n",
    "\n",
    "[df.count(), valid.count(), test.count()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text', 'string'), ('label', 'int')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the data type of each variable in the dataframe\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             label|\n",
      "+-------+------------------+\n",
      "|  count|             40000|\n",
      "|   mean|          0.499525|\n",
      "| stddev|0.5000060244893201|\n",
      "|    min|                 0|\n",
      "|    max|                 1|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. shows basic statistics for the numeric variables\n",
    "\n",
    "df.describe(['label']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|label|count(1)|\n",
      "+-----+--------+\n",
      "|    1|   19981|\n",
      "|    0|   20019|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Count the size of positive (=1) and negative (=0) reviews \n",
    "\n",
    "from pyspark.sql import functions as fn\n",
    "\n",
    "df.groupBy('label').agg(fn.count('*')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(text='Im a die hard Dads Army fan and nothing will ever change that. I got all the tapes, DVD\\'s and audiobooks and every time i watch/listen to them its brand new. <br /><br />The film. The film is a re run of certain episodes, Man and the hour, Enemy within the gates, Battle School and numerous others with a different edge. Introduction of a new General instead of Captain Square was a brilliant move - especially when he wouldn\\'t cash the cheque (something that is rarely done now).<br /><br />It follows through the early years of getting equipment and uniforms, starting up and training. All in all, its a great film for a boring Sunday afternoon. <br /><br />Two draw backs. One is the Germans bogus dodgy accents (come one, Germans cant pronounced the letter \"W\" like us) and Two The casting of Liz Frazer instead of the familiar Janet Davis. I like Liz in other films like the carry ons but she doesn\\'t carry it correctly in this and Janet Davis would have been the better choice.', label=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. show the first rows of positive reviews\n",
    "\n",
    "df.where(fn.col('label') == 1).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(text='I grew up (b. 1965) watching and loving the Thunderbirds. All my mates at school watched. We played \"Thunderbirds\" before school, during lunch and after school. We all wanted to be Virgil or Scott. No one wanted to be Alan. Counting down from 5 became an art form. I took my children to see the movie hoping they would get a glimpse of what I loved as a child. How bitterly disappointing. The only high point was the snappy theme tune. Not that it could compare with the original score of the Thunderbirds. Thankfully early Saturday mornings one television channel still plays reruns of the series Gerry Anderson and his wife created. Jonatha Frakes should hand in his directors chair, his version was completely hopeless. A waste of film. Utter rubbish. A CGI remake may be acceptable but replacing marionettes with Homo sapiens subsp. sapiens was a huge error of judgment.', label=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first rows of negative reviews\n",
    "\n",
    "df.where(fn.col('label') == 0).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Many preprocessing techniques can be used to prepare the text for sentiment analysis.\n",
    "- Here, we will apply three main techniques as follows:\n",
    "\n",
    "- 1. Tokenization: It is the process of splitting sentences into words. We are using the RegexTokenizer() function from the PySpark library that converts the sentences in the text column into individual terms in a words column. This process is essential to convert the words in a format that the Machine Learning model can accept.\n",
    "\n",
    "- 2. Remove Stop Words: Many words are considered unnecessary and unuseful in our analysis and need to be removed to make an accurate prediction. Here we request a list of stop words in English and use the PySpark stopWordsRemover() function to remove them from the words column and save the rest of the words in the filtered column.\n",
    "\n",
    "- 3. Term Frequency tf: Using the countVectorizer() function, we convert each term or word into a vector and count each term's frequency in each review. We specify the terms' size to 1000, and we ignore the terms that appear in 10 reviews or less.\n",
    "\n",
    "- 4. Pipelines: It combines all preprocessing work stages in one entity in which each stage is considered either a transformer or an estimator. The transformer is a function that adds, delete, or updates the current features in a dataframe, such as the tokenizer() and the stopWordsRemover(). On the other hand, the estimator such as the countVectorizer() and the LogisticRegression() in the next stage must learn from the input data and then returns a transformer. Any estimator has a fit() method that returns transformer() that is called when the pipeline gets executed [3]. \n",
    "\n",
    "- 5. Inverse Document Frequency IDF: It counts a term's appearance in the tf across all terms in all reviews. We then calculate the tf-IDF, which gives each term weight or a score indicating its importance (the high score is the important is the term). This technique helps in performing sentiment analysis by converting the words into vectors with different weights that can be understood by the ML Model [4].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. tokenize the text column (convert text into words)\n",
    "# first stage\n",
    "\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "\n",
    "tokenizer = RegexTokenizer().setGaps(False).setPattern('\\\\p{L}+').setInputCol('text').setOutputCol('words')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|                text|label|               words|\n",
      "+--------------------+-----+--------------------+\n",
      "|I grew up (b. 196...|    0|[i, grew, up, b, ...|\n",
      "|When I put this m...|    0|[when, i, put, th...|\n",
      "|Why do people who...|    0|[why, do, people,...|\n",
      "|Even though I hav...|    0|[even, though, i,...|\n",
      "|Im a die hard Dad...|    1|[im, a, die, hard...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. get stop words list from the link\n",
    "\n",
    "import requests\n",
    "stopWords = requests.get('http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words').text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words from words column and store the output in the filtered column\n",
    "# second stage\n",
    " \n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "filter = StopWordsRemover().setStopWords(stopWords).setCaseSensitive(False).setInputCol('words').setOutputCol('filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. use CountVectorizer to convert the filtered words to vectors of token counts (counts of Term Frecuency in documents)\n",
    "# remove words that appear in 10 documents or less\n",
    "# third stage\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(minTF=1., minDF=10., vocabSize=1000).setInputCol('filtered').setOutputCol('tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. create a pipelined transformer that group all previous stages in a single workflow\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "cv_pipeline = Pipeline(stages=[tokenizer, filter, cv]).fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|                text|label|               words|            filtered|                  tf|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|I grew up (b. 196...|    0|[i, grew, up, b, ...|[grew, b, watchin...|(1000,[2,3,43,71,...|\n",
      "|When I put this m...|    0|[when, i, put, th...|[movie, dvd, play...|(1000,[0,1,2,4,5,...|\n",
      "|Why do people who...|    0|[why, do, people,...|[people, know, pa...|(1000,[1,2,3,4,5,...|\n",
      "|Even though I hav...|    0|[even, though, i,...|[great, biblical,...|(1000,[2,8,10,11,...|\n",
      "|Im a die hard Dad...|    1|[im, a, die, hard...|[im, die, hard, d...|(1000,[0,1,3,4,5,...|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_pipeline.transform(df).show(5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. use Inverse Document Frequency to count the score of rare appeared terms \n",
    "from pyspark.ml.feature import IDF\n",
    "idf = IDF().setInputCol('tf').setOutputCol('tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create second pipeline that group the results from the last stage with this one\n",
    "idf_pipeline = Pipeline(stages=[cv_pipeline, idf]).fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|label|               words|            filtered|                  tf|               tfidf|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|I grew up (b. 196...|    0|[i, grew, up, b, ...|[grew, b, watchin...|(1000,[2,3,43,71,...|(1000,[2,3,43,71,...|\n",
      "|When I put this m...|    0|[when, i, put, th...|[movie, dvd, play...|(1000,[0,1,2,4,5,...|(1000,[0,1,2,4,5,...|\n",
      "|Why do people who...|    0|[why, do, people,...|[people, know, pa...|(1000,[1,2,3,4,5,...|(1000,[1,2,3,4,5,...|\n",
      "|Even though I hav...|    0|[even, though, i,...|[great, biblical,...|(1000,[2,8,10,11,...|(1000,[2,8,10,11,...|\n",
      "|Im a die hard Dad...|    1|[im, a, die, hard...|[im, die, hard, d...|(1000,[0,1,3,4,5,...|(1000,[0,1,3,4,5,...|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transform it to vectors representation and then show the first 5 rows\n",
    "\n",
    "idf_pipeline.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|label|               words|            filtered|                  tf|               tfidf|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|I grew up (b. 196...|    0|[i, grew, up, b, ...|[grew, b, watchin...|(1000,[2,3,43,71,...|(1000,[2,3,43,71,...|\n",
      "|When I put this m...|    0|[when, i, put, th...|[movie, dvd, play...|(1000,[0,1,2,4,5,...|(1000,[0,1,2,4,5,...|\n",
      "|Why do people who...|    0|[why, do, people,...|[people, know, pa...|(1000,[1,2,3,4,5,...|(1000,[1,2,3,4,5,...|\n",
      "|Even though I hav...|    0|[even, though, i,...|[great, biblical,...|(1000,[2,8,10,11,...|(1000,[2,8,10,11,...|\n",
      "|Im a die hard Dad...|    1|[im, a, die, hard...|[im, die, hard, d...|(1000,[0,1,3,4,5,...|(1000,[0,1,3,4,5,...|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_df = idf_pipeline.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Build a prodection model (Logestic Regrision Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression is a classification algorithm for categorical variables; we will use it to predict if the reviews are either positive = 1 or negative = 2.\n",
    "- 1. We will use the PySpark LogisticRegresion() function and set the 'label' column as a target and the 'tfidf' column as a feature.\n",
    "\n",
    "- 2. Create a pipeline to group the two stages and call the fit function to start the training. \n",
    "\n",
    "- 3. use the BinaryClassificationEvaluater() function to measure the accuracy of the model predictions. It gives a score of probability for the binary classes 0 and 1. The probability is either positive or negative value in which the negative one indicates that the review is = 0 and the positive probability indicates the review is = 1.\n",
    "\n",
    "- 4. Make a prediction using the validating dataset. Then evaluate the model accuracy, which can be calculated by dividing the count of the label equal to the prediction by the count of all entries. The roc-auc (Receiver Operating Characteristics-Area Under The Curve) score tells us how good our prediction curve is; the high the score, the better prediction is.\n",
    "\n",
    "- 5. Make another prediction using the test dataset and evaluate the results as well. We can see that the accuracy score is about 85 and the roc-auc score is 92, which is a good result. We can increase the accuracy by increasing the size of the words in the tfidf column. \n",
    "\n",
    "- 6. We can compare the actual label and the predicted one for each review.\n",
    "\n",
    "- 7. Finally, we can create a vocabulary of the positive and negative words based on their weights from the tfidf calculation, then show the top 20 negative and positive words in all reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. build the prediction model (Logistic Regression)\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression().setLabelCol('label').setFeaturesCol('tfidf').setRegParam(0.0).\\\n",
    "setMaxIter(100).setElasticNetParam(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. create a pipeline to group previous stage with the current one\n",
    "\n",
    "lr_pipeline = Pipeline(stages=[idf_pipeline, lr]).fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. evaluate accuracy of the classifier model \n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8530\n",
      "ROC-AUC: 0.9275\n"
     ]
    }
   ],
   "source": [
    "# 4. evaluate the prediction accuracy of the model ( use the validation set) \n",
    "\n",
    "predict = lr_pipeline.transform(valid)\n",
    "accuracy = predict.filter(predict.label == predict.prediction).count() / float(valid.count())\n",
    "roc_auc = evaluator.evaluate(predict)\n",
    "\n",
    "print(\"Accuracy Score: {0:.4f}\".format(accuracy))\n",
    "print(\"ROC-AUC: {0:.4f}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8614\n",
      "ROC-AUC: 0.9292\n"
     ]
    }
   ],
   "source": [
    "# 5. evaluate the prediction accuracy of the model ( use the test set) \n",
    "\n",
    "test_prediction = lr_pipeline.transform(test)\n",
    "\n",
    "accuracy = test_prediction.filter(test_prediction.label == test_prediction.prediction).count() / float(test.count())\n",
    "roc_auc = evaluator.evaluate(test_prediction)\n",
    "\n",
    "print(\"Accuracy Score: {0:.4f}\".format(accuracy))\n",
    "print(\"ROC-AUC: {0:.4f}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    1|       0.0|\n",
      "|    0|       0.0|\n",
      "|    1|       1.0|\n",
      "|    0|       0.0|\n",
      "|    1|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    1|       1.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. compare between the first 20 actual label and the predicted one \n",
    "\n",
    "test_prediction.select('label', 'prediction').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. create a vocabulary of a positive and negative words\n",
    "\n",
    "import pandas as pd\n",
    "vocabulary = idf_pipeline.stages[0].stages[-1].vocabulary\n",
    "weights = lr_pipeline.stages[-1].coefficients.toArray()\n",
    "coeffs_df = pd.DataFrame({'word': vocabulary, 'weight': weights})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>worst</td>\n",
       "      <td>-0.696979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>waste</td>\n",
       "      <td>-0.663751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>awful</td>\n",
       "      <td>-0.512901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>poorly</td>\n",
       "      <td>-0.403877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bad</td>\n",
       "      <td>-0.383148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>dull</td>\n",
       "      <td>-0.362985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>terrible</td>\n",
       "      <td>-0.352712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>boring</td>\n",
       "      <td>-0.352188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>fails</td>\n",
       "      <td>-0.338895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>wasted</td>\n",
       "      <td>-0.331485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>horrible</td>\n",
       "      <td>-0.329959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>worse</td>\n",
       "      <td>-0.325412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>lame</td>\n",
       "      <td>-0.317841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>pathetic</td>\n",
       "      <td>-0.315304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>avoid</td>\n",
       "      <td>-0.313546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>badly</td>\n",
       "      <td>-0.313061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>annoying</td>\n",
       "      <td>-0.306904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>pointless</td>\n",
       "      <td>-0.304101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>poor</td>\n",
       "      <td>-0.300947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>mess</td>\n",
       "      <td>-0.296304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word    weight\n",
       "103      worst -0.696979\n",
       "273      waste -0.663751\n",
       "202      awful -0.512901\n",
       "635     poorly -0.403877\n",
       "11         bad -0.383148\n",
       "528       dull -0.362985\n",
       "210   terrible -0.352712\n",
       "180     boring -0.352188\n",
       "778      fails -0.338895\n",
       "771     wasted -0.331485\n",
       "305   horrible -0.329959\n",
       "256      worse -0.325412\n",
       "624       lame -0.317841\n",
       "895   pathetic -0.315304\n",
       "574      avoid -0.313546\n",
       "678      badly -0.313061\n",
       "433   annoying -0.306904\n",
       "890  pointless -0.304101\n",
       "174       poor -0.300947\n",
       "735       mess -0.296304"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 20 negative words in all reviews\n",
    "\n",
    "coeffs_df.sort_values('weight').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>great</td>\n",
       "      <td>0.421380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>excellent</td>\n",
       "      <td>0.413530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>superb</td>\n",
       "      <td>0.335420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>amazing</td>\n",
       "      <td>0.334918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>0.313465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>best</td>\n",
       "      <td>0.310018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>fantastic</td>\n",
       "      <td>0.289580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>hilarious</td>\n",
       "      <td>0.278421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>brilliant</td>\n",
       "      <td>0.271617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>perfectly</td>\n",
       "      <td>0.262539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>perfect</td>\n",
       "      <td>0.261336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>loved</td>\n",
       "      <td>0.260505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>favorite</td>\n",
       "      <td>0.255628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>solid</td>\n",
       "      <td>0.239688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>enjoyed</td>\n",
       "      <td>0.238088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>surprised</td>\n",
       "      <td>0.230291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>highly</td>\n",
       "      <td>0.227781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>enjoyable</td>\n",
       "      <td>0.224018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>fun</td>\n",
       "      <td>0.218381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>surprisingly</td>\n",
       "      <td>0.210186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word    weight\n",
       "13          great  0.421380\n",
       "160     excellent  0.413530\n",
       "680        superb  0.335420\n",
       "303       amazing  0.334918\n",
       "229     wonderful  0.313465\n",
       "30           best  0.310018\n",
       "575     fantastic  0.289580\n",
       "392     hilarious  0.278421\n",
       "321     brilliant  0.271617\n",
       "696     perfectly  0.262539\n",
       "221       perfect  0.261336\n",
       "245         loved  0.260505\n",
       "335      favorite  0.255628\n",
       "958         solid  0.239688\n",
       "328       enjoyed  0.238088\n",
       "539     surprised  0.230291\n",
       "338        highly  0.227781\n",
       "518     enjoyable  0.224018\n",
       "101           fun  0.218381\n",
       "992  surprisingly  0.210186"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 20 positive words in all reviews\n",
    "\n",
    "coeffs_df.sort_values('weight', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- References\n",
    "- [1] Chand, S. (2020). PySpark Programming – Integrating Speed With Simplicity. Retrieved from https://www.edureka.co/blog/pyspark-programming/\n",
    "- [2] Spark ML. (n.d.). Introduction to Spark ML: An application to Sentiment Analysis. Retrieved from http://classes.ischool.syr.edu/ist718/content/unit09/lab-sentiment_analysis/\n",
    "- [3] Kumar, S. (2018). Machine Learning pipelines with Spark ML. Retrieved from https://medium.com/@Sushil_Kumar/machine-learning-pipelines-with-spark-ml-94cd9b4c973d\n",
    "- [4] How to process textual data using TF-IDF in Python. (n.d.). Retrieved from https://www.freecodecamp.org/news/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3/\n",
    "- [5] Introduction to Spark ML: An application to Sentiment Analysis (n.d.). http://classes.ischool.syr.edu/ist718/content/unit09/lab-sentiment_analysis/\n",
    "- [6] Kim, R. (2018). Sentiment Analysis with PySpark. Retrieved from https://towardsdatascience.com/sentiment-analysis-with-pyspark-bc8e83f80c35\n",
    "- [7] Narkhede, S. (2018). Understanding AUC - ROC Curve. Retrieved from https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
